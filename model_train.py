from sklearn.neighbors import KNeighborsClassifier  
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC
import xgboost as xgb
from sklearn.model_selection import train_test_split  
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score 
import logging
import time
import numpy as np 
import joblib

def KNN_train(X, y,model_path):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    logging.info("KNN_train")

    knn = KNeighborsClassifier(n_neighbors=3) 
    knn.fit(X_train, y_train)  
    #knn.fit(X, y)

    y_pred = knn.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred) 
    precision = precision_score(y_test,y_pred) 
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(classification_report(y_test, y_pred))
    print(f"Accuracy:{accuracy}")
    print(f"Precision:{precision}")
    print(f"recall:{recall}")
    print(f"f1:{f1}")
    logging.info(classification_report(y_test, y_pred))
    logging.info(f"Accuracy:{accuracy}")
    logging.info(f"Precision:{precision}")
    logging.info(f"recall:{recall}")
    logging.info(f"f1:{f1}")

    joblib.dump(knn, model_path)  
    logging.info(f"Model saved at {model_path}")

def SVM_train(X, y, model_path):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    logging.info("SVM_train")

    svm = SVC(kernel='linear', C=1.0, random_state=42) 
    #svm.fit(X, y)  
    svm.fit(X_train, y_train)  

    y_pred = svm.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred) 
    precision = precision_score(y_test,y_pred) 
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(classification_report(y_test, y_pred))
    print(f"Accuracy:{accuracy}")
    print(f"Precision:{precision}")
    print(f"recall:{recall}")
    print(f"f1:{f1}")
    logging.info(classification_report(y_test, y_pred))
    logging.info(f"Accuracy:{accuracy}")
    logging.info(f"Precision:{precision}")
    logging.info(f"recall:{recall}")
    logging.info(f"f1:{f1}")
    

    joblib.dump(svm, model_path)  
    logging.info(f"Model saved at {model_path}")

def RandomForest_train(X, y, model_path):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 ,random_state=42)
    logging.info("RandomForest_train")

    rf = RandomForestClassifier(n_estimators=20, max_depth=20, random_state=42)
    rf.fit(X_train, y_train) 
    y_pred = rf.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred) 
    precision = precision_score(y_test,y_pred) 
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(classification_report(y_test, y_pred))
    print(f"Accuracy:{accuracy}")
    print(f"Precision:{precision}")
    print(f"recall:{recall}")
    print(f"f1:{f1}")
    logging.info(classification_report(y_test, y_pred))
    logging.info(f"Accuracy:{accuracy}")
    logging.info(f"Precision:{precision}")
    logging.info(f"recall:{recall}")
    logging.info(f"f1:{f1}")
    joblib.dump(rf, model_path)  
    logging.info(f"Model saved at {model_path}")
    
def XGBoost_train(X, y, model_path):  
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  
    logging.info("XGBoost_train")  
  
  
    dtrain = xgb.DMatrix(X_train, label=y_train)  
    dtest = xgb.DMatrix(X_test, label=y_test)  
  
    params = {  
        'max_depth': 20,  
        'eta': 0.3,  
        'objective': 'binary:logistic' if len(set(y)) == 2 else 'multi:softmax',  
        'num_class': len(set(y)) if len(set(y)) > 2 else 1,  
        'eval_metric': 'mlogloss' if len(set(y)) == 2 else 'mlogloss'   
    }  
  
    num_round = 100  
    bst = xgb.train(params, dtrain, num_round)  
  
 
    y_pred = bst.predict(dtest)  
    if len(set(y)) > 2:  
        y_pred = [bst.predict(xgb.DMatrix([row]))[0].argmax() for row in X_test]  
    else:  
        y_pred = (y_pred > 0.5).astype(int) 
  
 
    accuracy = accuracy_score(y_test, y_pred)  
    precision = precision_score(y_test, y_pred, average='macro')  
    recall = recall_score(y_test, y_pred, average='macro')  
    f1 = f1_score(y_test, y_pred, average='macro')  
  
  
    print(classification_report(y_test, y_pred))  
    print(f"Accuracy: {accuracy}")  
    print(f"Precision: {precision}")  
    print(f"Recall: {recall}")  
    print(f"F1 Score: {f1}")  
  
    logging.info(classification_report(y_test, y_pred))  
    logging.info(f"Accuracy: {accuracy}")  
    logging.info(f"Precision: {precision}")  
    logging.info(f"Recall: {recall}")  
    logging.info(f"F1 Score: {f1}")  
  
    bst.save_model(model_path) 
    logging.info(f"Model saved at {model_path}")  
    
  
    

if __name__ == '__main__':
    logging.basicConfig(filename='./log/train.txt',  
                    level=logging.INFO,  
                    format='%(asctime)s - %(levelname)s - %(message)s')
    X = np.load('./feature_vector and labels/androzoo_feature.npy')  
    y = np.load('./feature_vector and labels/androzoo_label.npy')

    

    print(f"数据集形状{X.shape}")
   
    logging.info(f"\n----------------------------------start training----------------------------------------------")

    start_time = time.time()
   # KNN_train(X,y,'./model/androzoo_knn.pkl')
   # SVM_train(X, y,'./model/androzoo_svm.pkl')
    RandomForest_train(X,y,'./model/androzoo_rf.pkl')
    #XGBoost_train(X, y ,'./model/androzoo_xgboost.pkl')
    end_time = time.time()
    training_time = end_time - start_time
    print("Total training time: %f seconds", training_time)
    logging.info("Total training time: %f seconds", training_time)
    
    

   